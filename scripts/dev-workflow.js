import { StateGraph, START, END } from '@langchain/langgraph';
import { HumanMessage, SystemMessage } from '@langchain/core/messages';
import { spawn } from 'child_process';
import util from 'util';
import fs from 'fs/promises';
import readline from 'readline/promises';
import { stdin as input, stdout as output } from 'process';
import { fileURLToPath } from 'url';
import path from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// --- State Reducers ---

/**
 * Appends new messages to the existing history.
 * @param {Array} current - Current array of messages.
 * @param {Array} next - New messages to append.
 * @returns {Array} The updated message history.
 */
const aggregateMessages = (current, next) => current.concat(next);

/**
 * Updates the state with the latest value. 
 * If a new value is provided, it replaces the old one.
 * @param {any} current - Current value.
 * @param {any} next - New value.
 * @returns {any} The updated value.
 */
const updateLatest = (current, next) => next ? next : current;

// Define the state channels with clear descriptions
const agentStateChannels = {
  /**
   * The conversation history between the agents and the user.
   * Stores an array of LangChain Message objects.
   */
  messages: {
    value: aggregateMessages,
    default: () => [],
  },

  /**
   * The current technical plan generated by the Planner.
   * String content.
   */
  plan: {
    value: updateLatest,
    default: () => "",
  },

  /**
   * The latest feedback provided by the human user.
   * String content (e.g., "Approved", "Please fix X").
   */
  feedback: {
    value: updateLatest,
    default: () => "",
  },

  /**
   * The status of the coding phase.
   * Enum-like string: "pending", "coded".
   */
  code_status: {
    value: updateLatest,
    default: () => "pending",
  },

  /**
   * The output from the test runner.
   * String content containing pass/fail logs.
   */
  test_output: {
    value: updateLatest,
    default: () => "",
  },

  /**
   * The decision from the Reviewer agent.
   * Enum-like string: "pending", "approved", "rejected".
   */
  review_status: {
    value: updateLatest,
    default: () => "pending",
  }
};

/**
 * Manages the TDD development workflow using LangGraph and Gemini.
 * Orchestrates the planning, feedback, coding, testing, and review phases.
 * 
 * Uses the `gemini` CLI tool for LLM inference instead of direct API calls.
 */
export class WorkflowManager {
  constructor() {
    this.graph = null;
  }

  // --- Helpers ---

  /**
   * Invokes the Gemini CLI with a prompt.
   * Streams output to stdout and returns the full response.
   * @param {string} prompt - The prompt to send.
   * @param {Array} history - (Optional) Message history to contextualize the request.
   * @returns {Promise<string>} The generated response.
   */
  async invokeGemini(prompt, history = []) {
    return new Promise((resolve, reject) => {
      // With shell: false, we don't need to manually escape quotes.
      // Node.js will pass the prompt argument directly to the executable.
      
      const child = spawn('gemini', [prompt], {
        stdio: ['ignore', 'pipe', 'pipe'],
        shell: false 
      });

      let fullOutput = '';
      let errorOutput = '';

      child.stdout.on('data', (data) => {
        const chunk = data.toString();
        process.stdout.write(chunk); // Stream to console
        fullOutput += chunk;
      });

      child.stderr.on('data', (data) => {
        const chunk = data.toString();
        process.stderr.write(chunk); // Stream stderr to console
        errorOutput += chunk;
      });

      child.on('close', (code) => {
        if (code !== 0) {
          reject(new Error(`Gemini CLI exited with code ${code}: ${errorOutput}`));
        } else {
          resolve(fullOutput.trim());
        }
      });

      child.on('error', (err) => {
        reject(err);
      });
    });
  }

  // --- Tools ---
  
  /**
   * Reads a file from the filesystem.
   * @param {string} filePath - Path to the file.
   * @returns {Promise<string>} File content or error message.
   */
  async readFile(filePath) {
    try {
      return await fs.readFile(filePath, 'utf-8');
    } catch (error) {
      return `Error reading file: ${error.message}`;
    }
  }

  /**
   * Writes content to a file.
   * @param {string} filePath - Path to the file.
   * @param {string} content - Content to write.
   * @returns {Promise<string>} Success or error message.
   */
  async writeFile(filePath, content) {
    try {
      await fs.writeFile(filePath, content, 'utf-8');
      return `Successfully wrote to ${filePath}`;
    } catch (error) {
      return `Error writing file: ${error.message}`;
    }
  }

  // --- Nodes ---

  async planner(state) {
    const { messages } = state;
    console.log("--- Planner Node ---");
    
    // Extract the user's initial request or latest human message
    const lastMessage = messages[messages.length - 1];
    const userRequest = lastMessage.content;

    const systemPrompt = "You are a software architect. Create a detailed technical plan for the user's request.";
    const fullPrompt = `${systemPrompt}\n\nRequest: ${userRequest}`;

    const planContent = await this.invokeGemini(fullPrompt);
    console.log("\nPlan generated.");

    return { 
      plan: planContent,
      messages: [new SystemMessage(planContent)] 
    };
  }

  async humanFeedback(state) {
    const { plan } = state;
    console.log("--- Human Feedback Node ---");
    // Plan is already streamed to stdout by invokeGemini
    
    const rl = readline.createInterface({ input, output });
    
    try {
      const answer = await rl.question('\nDo you approve this plan? (yes/no/feedback): ');
      rl.close();

      if (answer.toLowerCase() === 'yes' || answer.toLowerCase() === 'y') {
        return { feedback: "Approved" };
      } else {
        return { feedback: answer };
      }
    } catch (error) {
      rl.close();
      return { feedback: "Error reading input, assuming rejection." };
    }
  }

  async coder(state) {
    const { plan, feedback, messages } = state;
    console.log("--- Coder Node ---");
    
    const systemPrompt = `You are a software engineer. Implement the following plan: ${plan}. 
    Previous Feedback: ${feedback}.
    You have access to the file system.
    For this step, please just output the code changes in markdown blocks.`;
    
    const codeContent = await this.invokeGemini(systemPrompt);
    console.log("\nCoding complete.");

    return { 
      code_status: "coded",
      messages: [new SystemMessage(codeContent)]
    };
  }

  async testRunner(state) {
    console.log("--- Test Runner Node ---");
    // Run tests
    try {
      // In a real scenario, we run the project's tests
      // const { stdout, stderr } = await execPromise('npm test');
      // return { test_output: stdout + stderr };
      
      console.log("Simulating tests passing...");
      return { test_output: "PASS" };
    } catch (error) {
      return { test_output: "FAIL: " + error.message };
    }
  }

  async reviewer(state) {
    const { plan, messages, test_output } = state;
    console.log("--- Reviewer Node ---");
    
    if (!test_output.includes("PASS")) {
       return { review_status: "rejected", messages: [new SystemMessage("Tests failed.")] };
    }

    const systemPrompt = "You are a senior reviewer. Review the implementation. Output 'Approved' if good, or feedback if not.";
    const reviewContent = await this.invokeGemini(systemPrompt);
    
    const isApproved = reviewContent.toLowerCase().includes("approved");
    console.log(`\nReview decision: ${isApproved ? "Approved" : "Rejected"}`);
    
    return { 
      review_status: isApproved ? "approved" : "rejected",
      messages: [new SystemMessage(reviewContent)]
    };
  }

  // --- Conditional Logic ---
  
  shouldContinueFromFeedback(state) {
    if (state.feedback === "Approved") {
      return "coder";
    }
    return "planner";
  }

  shouldContinueFromTest(state) {
    if (state.test_output && state.test_output.includes("PASS")) {
      return "reviewer";
    }
    return "coder";
  }

  shouldContinueFromReview(state) {
    if (state.review_status === "approved") {
      return END;
    }
    return "coder";
  }

  createGraph() {
    const workflow = new StateGraph({
      channels: agentStateChannels
    });

    // Add Nodes
    workflow.addNode("planner", this.planner.bind(this));
    workflow.addNode("human_feedback", this.humanFeedback.bind(this));
    workflow.addNode("coder", this.coder.bind(this));
    workflow.addNode("test_runner", this.testRunner.bind(this));
    workflow.addNode("reviewer", this.reviewer.bind(this));

    // Add Edges
    workflow.addEdge(START, "planner");
    workflow.addEdge("planner", "human_feedback");
    
    workflow.addConditionalEdges(
      "human_feedback",
      this.shouldContinueFromFeedback.bind(this),
      {
        coder: "coder",
        planner: "planner"
      }
    );

    workflow.addEdge("coder", "test_runner");

    workflow.addConditionalEdges(
      "test_runner",
      this.shouldContinueFromTest.bind(this),
      {
        reviewer: "reviewer",
        coder: "coder"
      }
    );

    workflow.addConditionalEdges(
      "reviewer",
      this.shouldContinueFromReview.bind(this),
      {
        [END]: END,
        coder: "coder"
      }
    );

    this.graph = workflow.compile();
    return this.graph;
  }

  async run(input) {
    if (!this.graph) {
      this.createGraph();
    }
    
    const initialState = {
      messages: [new HumanMessage(input)],
    };

    return await this.graph.invoke(initialState);
  }
}

// CLI Entry Point
if (process.argv[1] === __filename) {
  const prompt = process.argv[2];
  if (!prompt) {
    console.error("Please provide a prompt argument.");
    process.exit(1);
  }

  const workflow = new WorkflowManager();
  workflow.run(prompt).then((result) => {
    console.log("Workflow completed.");
  }).catch(err => {
    console.error("Workflow failed:", err);
  });
}
